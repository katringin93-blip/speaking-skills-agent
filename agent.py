import sys
import time
import subprocess
import os
from pathlib import Path
from typing import List, Tuple, Optional, Dict, Any

import yaml
import requests
from pydub import AudioSegment

# ---------- ÐšÐ¾Ð½ÑÑ‚Ð°Ð½Ñ‚Ñ‹ ----------
CHECK_INTERVAL_SECONDS = 2
CHUNK_LENGTH_MS = 300 * 1000  # 5 Ð¼Ð¸Ð½ÑƒÑ‚
TELEGRAM_SAFE_LIMIT = 3500  # ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚ Ð´Ð»Ñ Telegram (Ð·Ð°Ð¿Ð°Ñ Ðº Ð»Ð¸Ð¼Ð¸Ñ‚Ñƒ ~4096)

# ---------- Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ----------

def log(msg: str):
    ts = time.strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{ts}] {msg}")

# ---------- ÐŸÐ¾Ð¼Ð¾Ñ‰Ð½Ð¸ÐºÐ¸ ----------

def pause_and_exit(code: int = 0):
    print("\n---")
    print("ÐÐ°Ð¶Ð¼Ð¸Ñ‚Ðµ ENTER, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð·Ð°ÐºÑ€Ñ‹Ñ‚ÑŒ Ð¾ÐºÐ½Ð¾...")
    try:
        input()
    except Exception:
        pass
    sys.exit(code)

def app_base_dir() -> Path:
    if getattr(sys, "frozen", False):
        return Path(sys.executable).parent
    return Path(__file__).parent

def load_config() -> dict:
    base_path = app_base_dir()
    cfg_path = base_path / "config.local.yaml"
    if not cfg_path.exists():
        cfg_path = Path(os.getcwd()) / "config.local.yaml"
    if not cfg_path.exists():
        raise FileNotFoundError(f"ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð» Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½: {cfg_path}")
    return yaml.safe_load(cfg_path.read_text(encoding="utf-8")) or {}

def is_file_stable(path: Path, stable_seconds: int = 10, poll_interval: int = 1) -> bool:
    if not path.exists():
        return False
    last_size = path.stat().st_size
    stable_for = 0
    while stable_for < stable_seconds:
        time.sleep(poll_interval)
        if not path.exists():
            return False
        size = path.stat().st_size
        if size != last_size:
            last_size = size
            stable_for = 0
        else:
            stable_for += poll_interval
    return True

def _run_ffmpeg(cmd: List[str]) -> None:
    r = subprocess.run(cmd, capture_output=True, text=True)
    if r.returncode != 0:
        raise RuntimeError((r.stderr or r.stdout or "").strip())

# ---------- ÐÑƒÐ´Ð¸Ð¾ ----------

def extract_me_and_others(ffmpeg: Path, input_video: Path, out_dir: Path) -> Tuple[Path, Path]:
    me_wav = out_dir / "me.wav"
    others_wav = out_dir / "others.wav"
    _run_ffmpeg([str(ffmpeg), "-y", "-i", str(input_video), "-map", "0:a:1", str(me_wav)])
    _run_ffmpeg([str(ffmpeg), "-y", "-i", str(input_video), "-map", "0:a:0", str(others_wav)])
    return me_wav, others_wav

def clean_me_audio(ffmpeg: Path, me_wav: Path, out_dir: Path) -> Path:
    out = out_dir / "me_clean.wav"
    _run_ffmpeg([
        str(ffmpeg), "-y", "-i", str(me_wav),
        "-af", "highpass=f=120, lowpass=f=6000, afftdn",
        str(out)
    ])
    return out

def normalize_for_api(ffmpeg: Path, input_wav: Path, out_dir: Path) -> Path:
    out = out_dir / "me_clean_16k.wav"
    _run_ffmpeg([
        str(ffmpeg), "-y", "-i", str(input_wav),
        "-ac", "1", "-ar", "16000",
        str(out)
    ])
    return out

def slice_audio(audio_path: Path) -> List[Path]:
    audio = AudioSegment.from_file(audio_path)
    chunks = []
    for i, chunk in enumerate(audio[::CHUNK_LENGTH_MS]):
        p = audio_path.parent / f"chunk_{i}.mp3"
        chunk.export(p, format="mp3")
        chunks.append(p)
    return chunks

# ---------- Telegram ----------

def trim_for_telegram(text: str, limit: int) -> str:
    if len(text) <= limit:
        return text
    cut = text[:limit]
    last_nl = cut.rfind("\n")
    if last_nl > 300:
        cut = cut[:last_nl]
    return cut.rstrip() + "\nâ€¦"

def telegram_send_message(token: str, chat_id: str, text: str, use_markdown: bool):
    url = f"https://api.telegram.org/bot{token}/sendMessage"
    payload: Dict[str, Any] = {
        "chat_id": chat_id,
        "text": text,
        "disable_web_page_preview": True
    }
    if use_markdown:
        payload["parse_mode"] = "Markdown"
    r = requests.post(url, json=payload, timeout=30)
    if r.status_code != 200:
        raise RuntimeError(f"Telegram error: {r.status_code} {r.text[:300]}")

def get_telegram_settings(config: dict):
    tg = config.get("telegram") or {}
    if not tg.get("enabled"):
        return None
    token = str(tg.get("bot_token", "")).strip()
    chat_id = str(tg.get("chat_id", "")).strip()
    send_md = bool(tg.get("send_analysis_md", True))
    if not token or not chat_id:
        return None
    return {"token": token, "chat_id": chat_id, "send_md": send_md}

# ---------- OpenAI ----------

def transcribe_chunk(api_key: str, chunk_path: Path) -> str:
    with chunk_path.open("rb") as f:
        r = requests.post(
            "https://api.openai.com/v1/audio/transcriptions",
            headers={"Authorization": f"Bearer {api_key}"},
            files={"file": (chunk_path.name, f, "audio/mpeg")},
            data={"model": "gpt-4o-transcribe", "response_format": "text"},
            timeout=900
        )
    if r.status_code != 200:
        raise RuntimeError(f"Transcription failed: {r.status_code} {r.text[:300]}")
    return r.text.strip()

def analyze_full(api_key: str, transcript: str) -> str:
    prompt = f"""
You are an IELTS Speaking examiner.
You will be given a transcript and/or audio-based description of one speaker only.
There is no dialogue context.
Evaluate the speaker strictly according to IELTS Speaking Band Descriptors.

Important rules:

Assess only what is present in the speakerâ€™s speech.

Do not assume missing abilities.

Use the official 0â€“9 IELTS band scale (allow .5 scores).

Respond only in English.

Be concise, precise, and analytical.

Evaluation Criteria (all are mandatory)
1. Fluency and Coherence

Assign a band score (0â€“9 or .5).

Briefly explain the score.

Provide specific examples of issues or strengths, such as:

long or frequent pauses

hesitation due to word search

repetition or self-correction

weak or effective logical progression

overuse or lack of linking devices

2. Lexical Resource

Assign a band score (0â€“9 or .5).

Briefly explain the score.

Provide examples from the speech, including:

limited vocabulary or excessive repetition

incorrect word choice or collocation errors

successful or failed paraphrasing

inappropriate use of idiomatic language

precision vs vagueness

3. Grammatical Range and Accuracy

Assign a band score (0â€“9 or .5).

Briefly explain the score.

Give concrete examples, such as:

frequent basic sentence structures only

errors in tense, agreement, word order, articles, prepositions

attempts at complex structures (relative clauses, conditionals, subordination)

whether errors are systematic or occasional

4. Pronunciation

Assign a band score (0â€“9 or .5).

Briefly explain the score.

Provide examples or observations, including:

mispronounced sounds that affect understanding

word stress errors

sentence stress and intonation issues

rhythm and connected speech

degree to which accent interferes with intelligibility

Final Results

Overall IELTS Speaking Band Score

Calculate the average of the four criteria.

Round to the nearest 0.5 as per IELTS rules.

Estimated CEFR Level

Map the final band score to CEFR (B1 / B2 / C1 / C2).

Output Format (strict)

Fluency and Coherence: Band X.X
Explanation: â€¦
Error / example notes: â€¦

Lexical Resource: Band X.X
Explanation: â€¦
Error / example notes: â€¦

Grammatical Range and Accuracy: Band X.X
Explanation: â€¦
Error / example notes: â€¦

Pronunciation: Band X.X
Explanation: â€¦
Error / example notes: â€¦

Overall IELTS Speaking Band: X.X
Estimated CEFR Level: â€¦

TRANSCRIPT:
{transcript}
"""
    r = requests.post(
        "https://api.openai.com/v1/chat/completions",
        headers={"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"},
        json={
            "model": "gpt-4o",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.3
        },
        timeout=180
    )
    if r.status_code != 200:
        raise RuntimeError(f"AI full analysis failed: {r.status_code} {r.text[:300]}")
    return r.json()["choices"][0]["message"]["content"]

def analyze_short(api_key: str, transcript: str, full_report: str) -> str:
    prompt = f"""
You are an IELTS Speaking examiner.
Respond only in English.
Keep the full response under 3000 characters.

You MUST be consistent with the FULL REPORT below:
- Use the same band scores for each criterion and the same overall band and CEFR.
- Keep explanations short, but do not contradict the full report.

Output strictly in this format:

ðŸŽ¯ IELTS Speaking â€” Short Report

ðŸ—£ Fluency & Coherence: Band X.X â€” one-sentence rationale
ðŸ“š Lexical Resource: Band X.X â€” one-sentence rationale
ðŸ§  Grammar: Band X.X â€” one-sentence rationale
ðŸ”Š Pronunciation: Band X.X â€” one-sentence rationale

â­ Overall Band: X.X
ðŸ“ˆ CEFR: B1 / B2 / C1 / C2
ðŸ§© Top 2 priorities (next session):
1) ...
2) ...

FULL REPORT:
{full_report}

TRANSCRIPT (for reference):
{transcript}
"""
    r = requests.post(
        "https://api.openai.com/v1/chat/completions",
        headers={"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"},
        json={
            "model": "gpt-4o",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.2
        },
        timeout=180
    )
    if r.status_code != 200:
        raise RuntimeError(f"AI short analysis failed: {r.status_code} {r.text[:300]}")
    return r.json()["choices"][0]["message"]["content"]

# ---------- Main ----------

def main():
    log("Agent started")
    config = load_config()

    obs_dir = Path(config["paths"]["obs_recordings_dir"])
    sess_root = Path(config["paths"]["sessions_dir"])
    ffmpeg = Path(config["paths"]["ffmpeg_path"])
    api_key = config["whisper_api"]["api_key"]

    tg = get_telegram_settings(config)
    AudioSegment.converter = str(ffmpeg)

    seen = set()

    log(f"Watching OBS dir: {obs_dir}")
    log(f"Sessions dir: {sess_root}")
    log(f"Telegram enabled: {bool(tg)}")

    while True:
        try:
            files = list(obs_dir.iterdir())
        except Exception as e:
            log(f"ERROR: cannot read OBS dir: {e}")
            pause_and_exit(1)

        for f in files:
            if f.suffix.lower() not in (".mkv", ".mp4") or f in seen:
                continue

            if not is_file_stable(f):
                continue

            log(f"New recording detected: {f.name}")
            s_dir = sess_root / time.strftime("%Y-%m-%d_%H-%M-%S")
            s_dir.mkdir(parents=True, exist_ok=True)
            log(f"Session folder created: {s_dir}")

            try:
                log("Step 1/7: extracting me.wav and others.wav")
                me_wav, _others_wav = extract_me_and_others(ffmpeg, f, s_dir)

                log("Step 2/7: cleaning me.wav -> me_clean.wav")
                clean = clean_me_audio(ffmpeg, me_wav, s_dir)

                log("Step 3/7: normalizing for API (mono 16k)")
                norm = normalize_for_api(ffmpeg, clean, s_dir)

                log("Step 4/7: chunking audio")
                chunks = slice_audio(norm)
                log(f"Chunks created: {len(chunks)}")

                log("Step 5/7: transcribing chunks")
                texts: List[str] = []
                for i, c in enumerate(chunks, start=1):
                    log(f"  Transcribe chunk {i}/{len(chunks)}: {c.name}")
                    texts.append(transcribe_chunk(api_key, c))
                    try:
                        c.unlink(missing_ok=True)
                    except Exception:
                        pass

                transcript = "\n\n".join(texts).strip()
                transcript_path = s_dir / "transcript_me.txt"
                transcript_path.write_text(transcript, encoding="utf-8")
                log(f"Transcript saved: {transcript_path.name} ({len(transcript)} chars)")

                log("Step 6/7: generating FULL analysis (file)")
                full_report = analyze_full(api_key, transcript)
                full_path = s_dir / "ai_analysis_report_full.txt"
                full_path.write_text(full_report, encoding="utf-8")
                log(f"Full analysis saved: {full_path.name} ({len(full_report)} chars)")

                log("Step 7/7: generating SHORT analysis (Telegram)")
                short_report = analyze_short(api_key, transcript, full_report)

                if tg:
                    msg = trim_for_telegram(short_report, TELEGRAM_SAFE_LIMIT)
                    log(f"Sending Telegram message ({len(msg)} chars)")
                    telegram_send_message(
                        tg["token"],
                        tg["chat_id"],
                        msg,
                        use_markdown=tg["send_md"]
                    )
                    log("Telegram message sent")
                else:
                    log("Telegram disabled or not configured; skipping send")

                seen.add(f)
                log("Session completed")

            except Exception as e:
                log(f"ERROR during processing {f.name}: {e}")

        time.sleep(CHECK_INTERVAL_SECONDS)

if __name__ == "__main__":
    main()
